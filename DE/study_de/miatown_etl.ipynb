{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f1776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import schedule\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "spark = SparkSession.builder \\\n",
    "                    .config(\"spark.jar\", \"C:\\\\Users\\\\thehu\\\\OneDrive\\\\Mia_town\\\\IT\\\\Data\\\\DE\\\\study_de\\\\postgresql-42.7.5.jar\") \\\n",
    "                    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "#DATABASE\n",
    "host = 'localhost'\n",
    "dbname = 'miatown'\n",
    "user = 'postgres'\n",
    "password = input('hay nhap pass')\n",
    "port = '5432'\n",
    "driver = \"org.postgresql.Driver\"\n",
    "\n",
    "conn = psycopg2.connect(f'host= {host} \\\n",
    "                        dbname= {dbname} \\\n",
    "                        user= {user} \\\n",
    "                        password= {password} \\\n",
    "                        ')\n",
    "\n",
    "#set commit automaticaly\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "#PATH\n",
    "path = 'C:\\\\Users\\\\thehu\\\\OneDrive\\\\Mia_town\\\\IT\\\\Data\\\\MIATOWN\\\\raw\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38693d9",
   "metadata": {},
   "source": [
    "### SOURCE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CREATE TABLE\n",
    "# conn = psycopg2.connect(f'host= {host} \\\n",
    "#                         dbname= {dbname} \\\n",
    "#                         user= {user} \\\n",
    "#                         password= {password} \\\n",
    "#                         ')\n",
    "\n",
    "# #set commit automaticaly\n",
    "# conn.set_session(autocommit=True)\n",
    "# cur = conn.cursor()\n",
    "def create_database():\n",
    "    try:\n",
    "        cur.execute(\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS transaction(\n",
    "                    area VARCHAR,\n",
    "                    sub_area VARCHAR,\n",
    "                    table_id VARCHAR,\n",
    "                    table_name VARCHAR,\n",
    "                    trans_id VARCHAR,\n",
    "                    amount_origin INT,\n",
    "                    voucher_amount_paid INT,\n",
    "                    total_amount INT,\n",
    "                    trans_date DATE,\n",
    "                    voucher_name VARCHAR,\n",
    "                    customer_name VARCHAR,\n",
    "                    customer_phone VARCHAR);\n",
    "                    \n",
    "                    CREATE TABLE IF NOT EXISTS product(\n",
    "                    trans_id VARCHAR,\n",
    "                    trans_date DATE,\n",
    "                    item_name VARCHAR,\n",
    "                    category VARCHAR,\n",
    "                    quantity FLOAT,\n",
    "                    amount INT,\n",
    "                    amount_discount_on_price INT);\n",
    "\n",
    "                    \"\"\")\n",
    "    except psycopg2.Error as e:\n",
    "        print('error in creating table, table is existed')\n",
    "    return print(\"Database work finished\")\n",
    "\n",
    "\n",
    "def data_extract(path):\n",
    "    transaction_combine = None \n",
    "    print('----------  combine file  ----------')\n",
    "    print('----------  create transaction data  ----------')\n",
    "    json_file = [f'{path}{file}' for file in os.listdir(path) if file.endswith('.json')]        #print a list of exactly json file from folder\n",
    "    for file in json_file:\n",
    "        print(f'----------  Selecting from {file}  ----------')\n",
    "        raw = spark.read.json(file)\n",
    "        transaction = (\n",
    "                raw.withColumn('customer_name', col('extra_data.customer_name')) \\\n",
    "                    .withColumn('customer_phone', col('extra_data.customer_phone')) \\\n",
    "                    .withColumn('trans_id', col('tran_id')) \\\n",
    "                    # .withColumn('trans_id', col('sale_detail').getItem(0).getItem('tran_id')) \\\n",
    "                    .withColumn(\"trans_date\", (from_unixtime(col(\"created_at\") / 1000)).cast('timestamp') - expr(\"INTERVAL 7 HOURS\")) #set timezone manually\n",
    "                    .withColumn(\"area\", \n",
    "                                when((col(\"table_name\").contains(\"CAFE KIDS\")) | (col(\"table_name\").contains(\"QUẦY VÉ\")), \"KID\") \\\n",
    "                                .when(col(\"table_name\").contains(\"BIDA\"), \"BIDA\") \\\n",
    "                                .when(col(\"table_name\").contains(\"PS5\"), \"GAMING\") \\\n",
    "                                .otherwise(col(\"table_name\"))\n",
    "                                )\n",
    "                    .withColumn(\"sub_area\",\n",
    "                                when(col(\"table_name\").contains(\"NHÂN VIÊN\"), \"NHÂN VIÊN\") \\\n",
    "                                .when(col(\"table_name\").contains(\"BIDA LỖ\"), \"BIDA LỖ\") \\\n",
    "                                .when(col(\"table_name\").contains(\"BIDA BĂNG\"), \"BIDA BĂNG\") \\\n",
    "                                .when(col(\"table_name\").contains(\"BIDA LIBRE\"), \"BIDA LIBRE\") \\\n",
    "                                .when(col(\"table_name\").contains(\"ROOM\"), \"ROOM\") \\\n",
    "                                .when(col(\"table_name\").contains(\"GHẾ\"), \"GHẾ\") \\\n",
    "                                .when(col(\"table_name\").contains(\"CAFE KIDS\"), \"CAFE KIDS\") \\\n",
    "                                .when(col(\"table_name\").contains(\"QUẦY VÉ\"), \"QUẦY VÉ\")\n",
    "                                .otherwise(col(\"table_name\"))\n",
    "                                )\n",
    "        )\n",
    "        transaction = transaction.select(\n",
    "                    'area',\n",
    "                    'sub_area',\n",
    "                    'table_id',\n",
    "                    'table_name', \n",
    "                    'trans_id', \n",
    "                    'amount_origin',\n",
    "                    'voucher_amount_paid', \n",
    "                    'total_amount', \n",
    "                    'trans_date', \n",
    "                    'voucher_name', \n",
    "                    'customer_name',\n",
    "                    'customer_phone' )\n",
    "        print(f'----------  Union {file}  ----------')\n",
    "        transaction_combine = transaction if transaction_combine is None else transaction_combine.union(transaction)\n",
    "    print('----------  DONE  ----------')\n",
    "    \n",
    "\n",
    "    product_combine = None \n",
    "    print('----------  combine file  ----------')\n",
    "    print('----------  CREATE PRODUCT DATA  ----------')\n",
    "    json_file = [f'{path}{file}' for file in os.listdir(path) if file.endswith('.json')]        #print a list of exactly json file from folder\n",
    "    for file in json_file:\n",
    "        print(f'----------  Selecting from {file}  ----------')\n",
    "        raw = spark.read.json(file)\n",
    "        raw = raw.withColumn(\"sale\", explode(col(\"sale_detail\")))\n",
    "        raw = raw.withColumn(\"topping\", explode_outer(col(\"sale.toppings\")))\n",
    "                \n",
    "        product = raw.select(\n",
    "                                col(\"tran_id\").alias(\"trans_id\"),\n",
    "                                ((from_unixtime(col(\"created_at\") / 1000)).cast('timestamp') - expr(\"INTERVAL 7 HOURS\")).alias(\"trans_date\"),\n",
    "                                \"sale.item_name\",\n",
    "                                when(col(\"sale.item_name\").contains(\"COMBO\"), \"COMBO\").otherwise(col(\"sale.item_class_name\")).alias(\"category\"),\n",
    "                                \"sale.quantity\",\n",
    "                                \"sale.amount\",\n",
    "                                \"sale.amount_discount_on_price\"\n",
    "                                )\n",
    "\n",
    "        topping = raw.select(\n",
    "                                col(\"tran_id\").alias(\"trans_id\"),\n",
    "                                ((from_unixtime(col(\"created_at\") / 1000)).cast('timestamp') - expr(\"INTERVAL 7 HOURS\")).alias(\"trans_date\"),\n",
    "                                \"topping.item_name\",\n",
    "                                when(col(\"sale.item_name\").contains(\"COMBO\"), \"COMBO\").otherwise(col(\"sale.item_class_name\")).alias(\"category\"),\n",
    "                                \"topping.quantity\",\n",
    "                                \"topping.amount\",\n",
    "                                \"topping.amount_discount_on_price\"\n",
    "                    )\n",
    "        windowSpec = Window.partitionBy(\"trans_id\", \"item_name\").orderBy(col(\"trans_id\"))\n",
    "        product = product.withColumn(\"row_num\", row_number().over(windowSpec))\n",
    "        topping = topping.withColumn(\"row_num\", row_number().over(windowSpec))\n",
    "\n",
    "        #UPDATE LẠI SỐ LƯỢNG COMBO\n",
    "        combo_qty = product.groupBy(\"trans_id\").agg(max(col(\"row_num\")))\n",
    "        product = product.join(combo_qty, \"trans_id\", \"left\") \n",
    "        product = product.withColumn(\n",
    "                                    \"quantity\", \n",
    "                                    when(col(\"item_name\").contains(\"COMBO\"),\n",
    "                                            when(col(\"max(row_num)\") == 1, col(\"quantity\")).otherwise(                                                                            \n",
    "                                            when((col(\"max(row_num)\") % 2 != 0) & (col(\"max(row_num)\") > 1), col(\"max(row_num)\") / 3).otherwise(col(\"max(row_num)\") / 2)\n",
    "                                            )\n",
    "                                        ).otherwise(col(\"quantity\"))\n",
    "            ) \\\n",
    "                        .withColumn(\n",
    "                            \"amount\",\n",
    "                            when(col(\"item_name\").contains(\"COMBO\"), col(\"quantity\")*col(\"amount\")).otherwise(col(\"amount\"))\n",
    "                        )\n",
    "        \n",
    "        #Filtering\n",
    "        product = product.filter((col(\"item_name\") != \"COMBO SÁNG BIDA\") | (col(\"row_num\") == 1))\n",
    "        product = product.drop(\"max(row_num)\")\n",
    "        topping = topping.filter(col(\"topping.item_name\").isNotNull())\n",
    "        final_product = product.union(topping)\n",
    "        final_product = final_product.drop(\"row_num\")\n",
    "\n",
    "        print(f'----------  Union {file}  ----------')\n",
    "        product_combine = final_product if product_combine is None else product_combine.union(final_product)   \n",
    "\n",
    "    print('----------  DONE  ----------')\n",
    "\n",
    "    return transaction_combine, product_combine\n",
    "\n",
    "\n",
    "def load_data_to_database(transaction_combine, product_combine): ## ĐỂ Ý LẠI LÚC 2 BẢNG CHÊNH LỆCH DATA KHI IMPORT VÀO, TỐI ƯU LẠI \n",
    "    print('Connect to database')\n",
    "    url = f\"jdbc:postgresql://{host}:{port}/{dbname}\"\n",
    "    properties = {\n",
    "        \"user\": f\"{user}\",\n",
    "        \"password\": f\"{password}\",\n",
    "        \"driver\": f\"{driver}\"\n",
    "    }\n",
    "    print('Completed')\n",
    "\n",
    "    print(\"Checking database\")\n",
    "    transaction_query = \"(SELECT COUNT(*) AS row_count FROM transaction) as temp\"\n",
    "    count_old_data_trans = spark.read.jdbc(url, transaction_query, properties=properties)\n",
    "    transaction_row_count = count_old_data_trans.collect()[0][\"row_count\"]\n",
    "    old_data_trans = spark.read.jdbc(url ,\"(SELECT trans_id FROM transaction)\", properties = properties)\n",
    "\n",
    "    if transaction_row_count == 0:\n",
    "        print(\"Table 'transaction' is empty. Appending new data...\")\n",
    "        # Append data\n",
    "        transaction_combine.write.jdbc(url, \"transaction\", mode = 'append', properties = properties)\n",
    "        print(\"Data successfully appended to 'TRANSACTION' table.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Table 'transaction' already contains {transaction_row_count} rows. Checking for new data.\")\n",
    "        transaction_combine.createOrReplaceTempView(\"new_data_trans\")\n",
    "        old_data_trans.createOrReplaceTempView(\"old_data_trans\")\n",
    "        trans_checking = spark.sql( \"\"\"\n",
    "                SELECT trans_id from new_data_trans\n",
    "                EXCEPT\n",
    "                SELECT trans_id from old_data_trans\n",
    "    \"\"\")\n",
    "        new_trans_data = spark.sql(\"\"\"\n",
    "                                   with id AS(\n",
    "                                    SELECT trans_id from new_data_trans\n",
    "                                    EXCEPT\n",
    "                                    SELECT trans_id from old_data_trans\n",
    "                                   )\n",
    "                                   SELECT ndt.* \n",
    "                                   FROM id i\n",
    "                                   INNER JOIN new_data_trans ndt\n",
    "                                   ON i.trans_id = ndt.trans_id\n",
    "    \"\"\")\n",
    "        if trans_checking.count() == 0:\n",
    "            print(\"No new data, finished process\")\n",
    "        else:\n",
    "            print(f\"There's {trans_checking.count()} new data in transaction, appending....\" )\n",
    "            new_trans_data.write.jdbc(url, \"transaction\", mode = 'append', properties = properties )\n",
    "            print('Completed')\n",
    "\n",
    "\n",
    "    product_query = \"(SELECT COUNT(*) AS row_count FROM product) as temp_\"\n",
    "    count_old_data_prod = spark.read.jdbc(url, product_query, properties=properties)\n",
    "    product_row_count = count_old_data_prod.collect()[0][\"row_count\"]\n",
    "    old_data_prod = spark.read.jdbc(url ,\"(SELECT trans_id FROM product)\", properties = properties)\n",
    "\n",
    "    if product_row_count == 0:\n",
    "        print(\"Table 'product' is empty. Appending new data...\")\n",
    "        # Append data\n",
    "        product_combine.write.jdbc(url, \"product\", mode = 'append', properties = properties)\n",
    "        print(\"Data successfully appended to 'PRODUCT' table.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Table 'PRODUCT' already contains {product_row_count} rows. Checking for new data.\")\n",
    "        product_combine.createOrReplaceTempView(\"new_data_prod\")\n",
    "        old_data_prod.createOrReplaceTempView(\"old_data_prod\")\n",
    "        prod_checking = spark.sql( \"\"\"\n",
    "                SELECT trans_id from new_data_prod\n",
    "                EXCEPT\n",
    "                SELECT trans_id from old_data_prod\n",
    "    \"\"\")\n",
    "        new_prod_data = spark.sql(\"\"\"\n",
    "                                   with id AS(\n",
    "                                    SELECT trans_id from new_data_prod\n",
    "                                    EXCEPT\n",
    "                                    SELECT trans_id from old_data_prod\n",
    "                                   )\n",
    "                                   SELECT ndp.* \n",
    "                                   FROM id i\n",
    "                                   INNER JOIN new_data_prod ndp\n",
    "                                   ON i.trans_id = ndp.trans_id\n",
    "    \"\"\")\n",
    "        if prod_checking.count() == 0:\n",
    "            print(\"No new data, finished process\")\n",
    "        else:\n",
    "            print(f\"There's {prod_checking.count()} new data in product, appending....\" )\n",
    "            new_prod_data.write.jdbc(url, \"product\", mode = 'append', properties = properties )\n",
    "            print('Completed')\n",
    "    print(\"----------EXTRACT COMPLETE----------\")\n",
    "    # return new_trans_data, new_prod_data\n",
    "\n",
    "\n",
    "\n",
    "def main_task(path):\n",
    "    create_database()\n",
    "    transaction_combine, product_combine = data_extract(path)\n",
    "    result = load_data_to_database(transaction_combine, product_combine)\n",
    "    print(\"Finished\")\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9aaf5eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database work finished\n",
      "----------  combine file  ----------\n",
      "----------  create transaction data  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_18t05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_18t05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_19_05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_19_05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_1_17t05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_1_17t05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t04_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t04_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gaming_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gaming_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t04_2025.json  ----------\n",
      "----------  DONE  ----------\n",
      "----------  combine file  ----------\n",
      "----------  CREATE PRODUCT DATA  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_18t05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_18t05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_19_05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_19_05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_1_17t05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_1_17t05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t04_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t04_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gaming_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gaming_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t04_2025.json  ----------\n",
      "----------  DONE  ----------\n",
      "Connect to database\n",
      "Completed\n",
      "Checking database\n",
      "Table 'transaction' already contains 38061 rows. Checking for new data.\n",
      "No new data, finished process\n",
      "Table 'product' is empty. Appending new data...\n",
      "Data successfully appended to 'PRODUCT' table.\n",
      "----------EXTRACT COMPLETE----------\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\thehu\\\\OneDrive\\\\Mia_town\\\\IT\\\\Data\\\\MIATOWN\\\\raw\\\\'\n",
    "main_task(path)\n",
    "\n",
    "## CHECK LẠI CÁI UNION TRONG FUNC COMBINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9e00255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----------+---------------+--------------------+-------------+-------------------+------------+-------------------+------------+-------------+--------------+\n",
      "|area|sub_area|  table_id|     table_name|            trans_id|amount_origin|voucher_amount_paid|total_amount|         trans_date|voucher_name|customer_name|customer_phone|\n",
      "+----+--------+----------+---------------+--------------------+-------------+-------------------+------------+-------------------+------------+-------------+--------------+\n",
      "|BIDA| BIDA LỖ|TABLE-1M2D|Bàn 9 - BIDA LỖ|4PW46ZJ6VPRKF3AKY...|     165945.0|                0.0|    165945.0|2025-04-01 05:28:42|            |    Giang Kuu|   84931915988|\n",
      "+----+--------+----------+---------------+--------------------+-------------+-------------------+------------+-------------------+------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction_combine.filter(col(\"trans_id\").contains(\"TIDM1\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe61b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import schedule\n",
    "# import time\n",
    "# import os\n",
    "\n",
    "# def run_etl():\n",
    "#     print(\"Starting ETL Process...\")\n",
    "#     os.system(\"python C:\\\\Users\\\\thehu\\\\OneDrive\\\\Mia_town\\\\IT\\\\Data\\\\ETL\\\\etl_script.py\")\n",
    "#     print(\"ETL Process Completed.\")\n",
    "\n",
    "# # Schedule the job to run daily at 11:30 AM\n",
    "# schedule.every().day.at(\"11:30\").do(run_etl)\n",
    "\n",
    "# while True:\n",
    "#     schedule.run_pending()\n",
    "#     time.sleep(60)  # Check every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ff307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------------+--------+--------+--------+------------------------+-------+\n",
      "|             tran_id|         trans_date|      item_name|category|quantity|  amount|amount_discount_on_price|row_num|\n",
      "+--------------------+-------------------+---------------+--------+--------+--------+------------------------+-------+\n",
      "|4PW46ZJ6VPRK20SFX...|2025-05-02 09:09:14|COMBO SÁNG BIDA|   COMBO|     1.0| 58000.0|                       0|      1|\n",
      "|4PW46ZJ6VPRKK7WGT...|2025-05-02 09:58:49|COMBO SÁNG BIDA|   COMBO|     1.0| 58000.0|                       0|      1|\n",
      "|4PW46ZJ6VPRKK7WH2...|2025-05-02 10:02:46|COMBO SÁNG BIDA|   COMBO|     1.0| 58000.0|                       0|      1|\n",
      "|P63JDN7MGD2P7A1LN...|2025-05-02 14:12:35|COMBO SÁNG BIDA|   COMBO|     4.0|232000.0|                       0|      1|\n",
      "+--------------------+-------------------+---------------+--------+--------+--------+------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# product_combine.filter(col(\"item_name\").contains(\"COMBO SÁNG\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23c3735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_database(transaction_combine, product_combine): ## ĐỂ Ý LẠI LÚC 2 BẢNG CHÊNH LỆCH DATA KHI IMPORT VÀO, TỐI ƯU LẠI \n",
    "    print('Connect to database')\n",
    "    url = f\"jdbc:postgresql://{host}:{port}/{dbname}\"\n",
    "    properties = {\n",
    "        \"user\": f\"{user}\",\n",
    "        \"password\": f\"{password}\",\n",
    "        \"driver\": f\"{driver}\"\n",
    "    }\n",
    "    print('Completed')\n",
    "\n",
    "    print(\"Checking database\")\n",
    "    transaction_query = \"(SELECT COUNT(*) AS row_count FROM transaction) as temp\"\n",
    "    count_old_data_trans = spark.read.jdbc(url, transaction_query, properties=properties)\n",
    "    transaction_row_count = count_old_data_trans.collect()[0][\"row_count\"]\n",
    "    old_data_trans = spark.read.jdbc(url ,\"(SELECT trans_id FROM transaction)\", properties = properties)\n",
    "\n",
    "    if transaction_row_count == 0:\n",
    "        print(\"Table 'transaction' is empty. Appending new data...\")\n",
    "        # Append data\n",
    "        transaction_combine.write.jdbc(url, \"transaction\", mode = 'append', properties = properties)\n",
    "        print(\"Data successfully appended to 'TRANSACTION' table.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Table 'transaction' already contains {transaction_row_count} rows. Checking for new data.\")\n",
    "        transaction_combine.createOrReplaceTempView(\"new_data_trans\")\n",
    "        old_data_trans.createOrReplaceTempView(\"old_data_trans\")\n",
    "        trans_checking = spark.sql( \"\"\"\n",
    "                SELECT trans_id from new_data_trans\n",
    "                EXCEPT\n",
    "                SELECT trans_id from old_data_trans\n",
    "    \"\"\")\n",
    "        new_trans_data = spark.sql(\"\"\"\n",
    "                                   with id AS(\n",
    "                                    SELECT trans_id from new_data_trans\n",
    "                                    EXCEPT\n",
    "                                    SELECT trans_id from old_data_trans\n",
    "                                   )\n",
    "                                   SELECT ndt.* \n",
    "                                   FROM id i\n",
    "                                   INNER JOIN new_data_trans ndt\n",
    "                                   ON i.trans_id = ndt.trans_id\n",
    "    \"\"\")\n",
    "        if trans_checking.count() == 0:\n",
    "            print(\"No new data, finished process\")\n",
    "        else:\n",
    "            print(f\"There's {trans_checking.count()} new data in transaction, appending....\" )\n",
    "            new_trans_data.write.jdbc(url, \"transaction\", mode = 'append', properties = properties )\n",
    "            print('Completed')\n",
    "\n",
    "\n",
    "    product_query = \"(SELECT COUNT(*) AS row_count FROM product) as temp_\"\n",
    "    count_old_data_prod = spark.read.jdbc(url, product_query, properties=properties)\n",
    "    product_row_count = count_old_data_prod.collect()[0][\"row_count\"]\n",
    "    old_data_prod = spark.read.jdbc(url ,\"(SELECT trans_id FROM product)\", properties = properties)\n",
    "\n",
    "    if product_row_count == 0:\n",
    "        print(\"Table 'product' is empty. Appending new data...\")\n",
    "        # Append data\n",
    "        product_combine.write.jdbc(url, \"product\", mode = 'append', properties = properties)\n",
    "        print(\"Data successfully appended to 'PRODUCT' table.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Table 'PRODUCT' already contains {product_row_count} rows. Checking for new data.\")\n",
    "        product_combine.createOrReplaceTempView(\"new_data_prod\")\n",
    "        old_data_prod.createOrReplaceTempView(\"old_data_prod\")\n",
    "        prod_checking = spark.sql( \"\"\"\n",
    "                SELECT trans_id from new_data_prod\n",
    "                EXCEPT\n",
    "                SELECT trans_id from old_data_prod\n",
    "    \"\"\")\n",
    "        new_prod_data = spark.sql(\"\"\"\n",
    "                                   with id AS(\n",
    "                                    SELECT trans_id from new_data_prod\n",
    "                                    EXCEPT\n",
    "                                    SELECT trans_id from old_data_prod\n",
    "                                   )\n",
    "                                   SELECT ndp.* \n",
    "                                   FROM id i\n",
    "                                   INNER JOIN new_data_prod ndp\n",
    "                                   ON i.trans_id = ndp.trans_id\n",
    "    \"\"\")\n",
    "        if prod_checking.count() == 0:\n",
    "            print(\"No new data, finished process\")\n",
    "        else:\n",
    "            print(f\"There's {prod_checking.count()} new data in product, appending....\" )\n",
    "            new_prod_data.write.jdbc(url, \"product\", mode = 'append', properties = properties )\n",
    "            print('Completed')\n",
    "    print(\"----------EXTRACT COMPLETE----------\")\n",
    "    return new_trans_data, new_prod_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b0fbb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  combine file  ----------\n",
      "----------  create transaction data  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_18t05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_18t05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_19_05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_19_05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_1_17t05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_1_17t05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t04_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t04_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gaming_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gaming_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t04_2025.json  ----------\n",
      "----------  DONE  ----------\n",
      "----------  combine file  ----------\n",
      "----------  CREATE PRODUCT DATA  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_18t05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_18t05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_19_05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_19_05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_1_17t05_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_1_17t05_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\bida_t04_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gamingps_t04_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gaming_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\gaming_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t01_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t01_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t02_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t02_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t03_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t03_2025.json  ----------\n",
      "----------  Selecting from C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t04_2025.json  ----------\n",
      "----------  Union C:\\Users\\thehu\\OneDrive\\Mia_town\\IT\\Data\\MIATOWN\\raw\\kid_t04_2025.json  ----------\n",
      "----------  DONE  ----------\n",
      "Connect to database\n",
      "Completed\n",
      "Checking database\n",
      "Table 'transaction' already contains 38061 rows. Checking for new data.\n",
      "No new data, finished process\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o34951.jdbc.\n: org.postgresql.util.PSQLException: ERROR: relation \"product\" does not exist\n  Position: 50\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:372)\r\n\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:517)\r\n\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:434)\r\n\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194)\r\n\tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:137)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:68)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\r\n\tat org.apache.spark.sql.DataFrameReader.jdbc(DataFrameReader.scala:249)\r\n\tat jdk.internal.reflect.GeneratedMethodAccessor135.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:842)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mthehu\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mMia_town\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mIT\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mMIATOWN\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m transaction_combine, product_combine \u001b[38;5;241m=\u001b[39m data_extract(path)\n\u001b[1;32m----> 6\u001b[0m new_trans_data, new_prod_data \u001b[38;5;241m=\u001b[39m load_data_to_database(transaction_combine, product_combine)\n",
      "Cell \u001b[1;32mIn[35], line 52\u001b[0m, in \u001b[0;36mload_data_to_database\u001b[1;34m(transaction_combine, product_combine)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m product_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(SELECT COUNT(*) AS row_count FROM product) as temp_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 52\u001b[0m count_old_data_prod \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mjdbc(url, product_query, properties\u001b[38;5;241m=\u001b[39mproperties)\n\u001b[0;32m     53\u001b[0m product_row_count \u001b[38;5;241m=\u001b[39m count_old_data_prod\u001b[38;5;241m.\u001b[39mcollect()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow_count\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     54\u001b[0m old_data_prod \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mjdbc(url ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(SELECT trans_id FROM product)\u001b[39m\u001b[38;5;124m\"\u001b[39m, properties \u001b[38;5;241m=\u001b[39m properties)\n",
      "File \u001b[1;32mc:\\Users\\thehu\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:946\u001b[0m, in \u001b[0;36mDataFrameReader.jdbc\u001b[1;34m(self, url, table, column, lowerBound, upperBound, numPartitions, predicates, properties)\u001b[0m\n\u001b[0;32m    944\u001b[0m     jpredicates \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtoJArray(gateway, gateway\u001b[38;5;241m.\u001b[39mjvm\u001b[38;5;241m.\u001b[39mjava\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39mString, predicates)\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mjdbc(url, table, jpredicates, jprop))\n\u001b[1;32m--> 946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mjdbc(url, table, jprop))\n",
      "File \u001b[1;32mc:\\Users\\thehu\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\thehu\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\thehu\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o34951.jdbc.\n: org.postgresql.util.PSQLException: ERROR: relation \"product\" does not exist\n  Position: 50\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:372)\r\n\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:517)\r\n\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:434)\r\n\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194)\r\n\tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:137)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:68)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\r\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\r\n\tat org.apache.spark.sql.DataFrameReader.jdbc(DataFrameReader.scala:249)\r\n\tat jdk.internal.reflect.GeneratedMethodAccessor135.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:842)\r\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\thehu\\\\OneDrive\\\\Mia_town\\\\IT\\\\Data\\\\MIATOWN\\\\raw\\\\'\n",
    "transaction_combine, product_combine = data_extract(path)\n",
    "\n",
    "\n",
    "\n",
    "new_trans_data, new_prod_data = load_data_to_database(transaction_combine, product_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+--------+--------+------+------------------------+\n",
      "|trans_id|trans_date|item_name|category|quantity|amount|amount_discount_on_price|\n",
      "+--------+----------+---------+--------+--------+------+------------------------+\n",
      "+--------+----------+---------+--------+--------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_prod_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9407fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d5eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85c83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b2d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043c612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3f0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343fd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff2395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4e3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbdba4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97d52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79561f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
